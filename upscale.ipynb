{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb67883e",
   "metadata": {},
   "source": [
    "# Upscale Images\n",
    "\n",
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a896a3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as F\n",
    "from src.esrgan import RRDBNet\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc9cf46",
   "metadata": {},
   "source": [
    "Function to Load Model saved in ./models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "378265df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path, device):\n",
    "    \"\"\"\n",
    "    Load an ESRGAN RRDBNet generator from a checkpoint.\n",
    "\n",
    "    Args:\n",
    "        model_path (str): Path to the .pth checkpoint file.\n",
    "        device (str or torch.device): Device to load the model onto (e.g. \"cpu\" or \"cuda\").\n",
    "\n",
    "    Returns:\n",
    "        RRDBNet: The generator model moved to `device` and set to eval() mode.\n",
    "    \"\"\"\n",
    "    print(f\"Loading model from: {model_path}\")\n",
    "    generator = RRDBNet().to(device)\n",
    "    generator.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    generator.eval()\n",
    "    print(\"Model loaded successfully!\")\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e265aa",
   "metadata": {},
   "source": [
    "Function to Upscale Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5db3a57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale_image(generator, lr_image_path, output_path, device):\n",
    "    print(f\"Loading image: {lr_image_path}\")\n",
    "    lr = Image.open(lr_image_path).convert(\"RGB\")\n",
    "    original_size = lr.size\n",
    "    print(f\"Original size: {original_size[0]}x{original_size[1]}\")\n",
    "    \n",
    "    lr_t = F.to_tensor(lr).unsqueeze(0).to(device)\n",
    "    \n",
    "    print(\"Upscaling...\")\n",
    "    with torch.no_grad():\n",
    "        sr = generator(lr_t)\n",
    "    \n",
    "    sr = torch.clamp(sr, 0, 1)\n",
    "    sr_img = F.to_pil_image(sr.squeeze(0).cpu())\n",
    "    \n",
    "    sr_img.save(output_path)\n",
    "    upscaled_size = sr_img.size\n",
    "    print(f\"Upscaled size: {upscaled_size[0]}x{upscaled_size[1]}\")\n",
    "    print(f\"Saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4014242",
   "metadata": {},
   "source": [
    "Function to Compare Original and Upscaled Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc885b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison(lr, sr):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "    axes[0, 0].imshow(lr)\n",
    "    axes[0, 0].set_title(\"Original Image (Full)\")\n",
    "    axes[0, 0].axis(\"off\")\n",
    "\n",
    "    axes[0, 1].imshow(sr)\n",
    "    axes[0, 1].set_title(\"Upscaled Image (Full)\")\n",
    "    axes[0, 1].axis(\"off\")\n",
    "\n",
    "    zoom_size = 200\n",
    "    lr_width, lr_height = lr.size\n",
    "    sr_width, sr_height = sr.size\n",
    "\n",
    "    max_x = max(0, lr_width - zoom_size)\n",
    "    max_y = max(0, lr_height - zoom_size)\n",
    "\n",
    "    if max_x > 0 and max_y > 0:\n",
    "        x = random.randint(0, max_x)\n",
    "        y = random.randint(0, max_y)\n",
    "\n",
    "        zoom_box_lr = (x, y, x + zoom_size, y + zoom_size)\n",
    "        zoom_box_sr = (x * 4, y * 4, (x + zoom_size) * 4, (y + zoom_size) * 4)\n",
    "        \n",
    "        lr_zoom = lr.crop(zoom_box_lr)\n",
    "        sr_zoom = sr.crop(zoom_box_sr)\n",
    "        \n",
    "        axes[1, 0].imshow(lr_zoom)\n",
    "        axes[1, 0].set_title(f\"Original - Zoomed\")\n",
    "        axes[1, 0].axis(\"off\")\n",
    "        \n",
    "        axes[1, 1].imshow(sr_zoom)\n",
    "        axes[1, 1].set_title(f\"Upscaled - Zoomed\")\n",
    "        axes[1, 1].axis(\"off\")\n",
    "    else:\n",
    "        axes[1, 0].text(0.5, 0.5, \"Image too small for zoom\", ha='center', va='center')\n",
    "        axes[1, 1].text(0.5, 0.5, \"Image too small for zoom\", ha='center', va='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f4ecd1",
   "metadata": {},
   "source": [
    "### Important Parameters\n",
    "- device: GPU is highly preferred, CPU would work but would be painfully slow.\n",
    "- model_path: ./models has ESRGAN.pth and ESRGAN_PSNR.pth. Only use the ESRGAN.pth, the other one is Phase 1 (PSNR) Trained only.\n",
    "- input_image: You can place the image anywhere, preferably in ./images.\n",
    "- output_path: You can place it anywhere, preferably in ./images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "50ea4fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\\n\")\n",
    "model_path = \"models/ESRGAN.pth\"\n",
    "input_image = \"images/test.jpg\"\n",
    "output_path = \"images/example_output_4.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511bfdb1",
   "metadata": {},
   "source": [
    "4x Upscale your Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813b8f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = load_model(model_path, device)\n",
    "upscale_image(generator, input_image, output_path, device)\n",
    "\n",
    "lr = Image.open(input_image).convert(\"RGB\")\n",
    "sr = Image.open(output_path).convert(\"RGB\")\n",
    "\n",
    "comparison(lr, sr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
